{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed995270-7929-4dd2-bd99-73de76ea83ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:32:48.582450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 15:32:48.648539: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "## EDIT:\n",
    "base_dir = '/glade/work/kjmayer/research/catalyst/TransferLearning/runmean_analysis/artificial_bias/perfectmodel_TLtest/E3SM_analysis/'\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(base_dir+'functions/')\n",
    "from utils import split_retrain\n",
    "from exp_hp import get_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71ed589-4362-4554-8611-1f7ef31d6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(inputs, top_pred_idx=None):\n",
    "    \"\"\"Computes the gradients of outputs w.r.t input image.\n",
    "\n",
    "    Args:\n",
    "        inputs: 2D/3D/4D matrix of samples\n",
    "        top_pred_idx: (optional) Predicted label for the x_data\n",
    "                      if classification problem. If regression,\n",
    "                      do not include.\n",
    "\n",
    "    Returns:\n",
    "        Gradients of the predictions w.r.t img_input\n",
    "    \"\"\"\n",
    "    inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inputs)\n",
    "        \n",
    "        # Run the forward pass of the layer and record operations\n",
    "        # on GradientTape.\n",
    "        preds = model(inputs, training=False)  \n",
    "        \n",
    "        # For classification, grab the top class\n",
    "        if top_pred_idx is not None:\n",
    "            preds = preds[:, top_pred_idx]\n",
    "        \n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.        \n",
    "    grads = tape.gradient(preds, inputs)\n",
    "    return grads\n",
    "\n",
    "def get_integrated_gradients(inputs, baseline=None, num_steps=50, top_pred_idx=None):\n",
    "    \"\"\"Computes Integrated Gradients for a prediction.\n",
    "\n",
    "    Args:\n",
    "        inputs (ndarray): 2D/3D/4D matrix of samples\n",
    "        baseline (ndarray): The baseline image to start with for interpolation\n",
    "        num_steps: Number of interpolation steps between the baseline\n",
    "            and the input used in the computation of integrated gradients. These\n",
    "            steps along determine the integral approximation error. By default,\n",
    "            num_steps is set to 50.\n",
    "        top_pred_idx: (optional) Predicted label for the x_data\n",
    "                      if classification problem. If regression,\n",
    "                      do not include.            \n",
    "\n",
    "    Returns:\n",
    "        Integrated gradients w.r.t input image\n",
    "    \"\"\"\n",
    "    # If baseline is not provided, start with zeros\n",
    "    # having same size as the input image.\n",
    "    if baseline is None:\n",
    "        input_size = np.shape(inputs)[1:]\n",
    "        baseline = np.zeros(input_size).astype(np.float32)\n",
    "    else:\n",
    "        baseline = baseline.astype(np.float32)\n",
    "\n",
    "    # 1. Do interpolation.\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    interpolated_inputs = [\n",
    "        baseline + (step / num_steps) * (inputs - baseline)\n",
    "        for step in range(num_steps + 1)\n",
    "    ]\n",
    "    interpolated_inputs = np.array(interpolated_inputs).astype(np.float32)\n",
    "\n",
    "    # 3. Get the gradients\n",
    "    grads = []\n",
    "    for i, x_data in enumerate(interpolated_inputs):\n",
    "        grad = get_gradients(x_data, top_pred_idx=top_pred_idx)     \n",
    "        grads.append(grad)\n",
    "    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n",
    "\n",
    "    # 4. Approximate the integral using the trapezoidal rule\n",
    "    grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "    avg_grads = tf.reduce_mean(grads, axis=0)\n",
    "    # 5. Calculate integrated gradients and return\n",
    "    integrated_grads = (inputs - baseline) * avg_grads\n",
    "    return integrated_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0878367-e14e-43c1-83b6-91a228525539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Member: 0291\n",
      "Testing Member: 0301\n",
      "3\n",
      "Training Members: ['0201', '0211', '0221', '0231']\n",
      "loading data & saving\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:33:55.544635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step\n",
      "1\n",
      "242/242 [==============================] - 1s 2ms/step\n",
      "2\n",
      "242/242 [==============================] - 0s 1ms/step\n",
      "3\n",
      "242/242 [==============================] - 0s 1ms/step\n",
      "4\n",
      "242/242 [==============================] - 0s 1ms/step\n",
      "5\n",
      "242/242 [==============================] - 0s 809us/step\n",
      "6\n",
      "242/242 [==============================] - 0s 762us/step\n",
      "7\n",
      "242/242 [==============================] - 0s 897us/step\n",
      "8\n",
      "242/242 [==============================] - 0s 801us/step\n",
      "9\n",
      "242/242 [==============================] - 0s 2ms/step\n",
      "4\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241']\n",
      "loading data & saving\n",
      "0\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "1\n",
      "239/239 [==============================] - 0s 815us/step\n",
      "2\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "3\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "4\n",
      "239/239 [==============================] - 0s 767us/step\n",
      "5\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "6\n",
      "239/239 [==============================] - 0s 775us/step\n",
      "7\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "8\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "9\n",
      "239/239 [==============================] - 0s 1ms/step\n",
      "5\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241', '0251']\n",
      "loading data & saving\n",
      "0\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "1\n",
      "240/240 [==============================] - 0s 750us/step\n",
      "2\n",
      "240/240 [==============================] - 0s 786us/step\n",
      "3\n",
      "240/240 [==============================] - 0s 741us/step\n",
      "4\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "5\n",
      "240/240 [==============================] - 0s 767us/step\n",
      "6\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "7\n",
      "240/240 [==============================] - 0s 764us/step\n",
      "8\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "9\n",
      "240/240 [==============================] - 0s 784us/step\n",
      "6\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241', '0251', '0261']\n",
      "loading data & saving\n",
      "0\n",
      "241/241 [==============================] - 0s 740us/step\n",
      "1\n",
      "241/241 [==============================] - 0s 836us/step\n",
      "2\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "3\n",
      "241/241 [==============================] - 0s 786us/step\n",
      "4\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "5\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "6\n",
      "241/241 [==============================] - 0s 739us/step\n",
      "7\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "8\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "9\n",
      "241/241 [==============================] - 0s 767us/step\n",
      "7\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241', '0251', '0261', '0271']\n",
      "loading data & saving\n",
      "0\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "1\n",
      "241/241 [==============================] - 0s 811us/step\n",
      "2\n",
      "241/241 [==============================] - 0s 789us/step\n",
      "3\n",
      "241/241 [==============================] - 0s 798us/step\n",
      "4\n",
      "241/241 [==============================] - 0s 785us/step\n",
      "5\n",
      "241/241 [==============================] - 0s 789us/step\n",
      "6\n",
      "241/241 [==============================] - 0s 796us/step\n",
      "7\n",
      "241/241 [==============================] - 0s 794us/step\n",
      "8\n",
      "241/241 [==============================] - 0s 1ms/step\n",
      "9\n",
      "241/241 [==============================] - 0s 753us/step\n",
      "8\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241', '0251', '0261', '0271', '0281']\n",
      "loading data & saving\n",
      "0\n",
      "240/240 [==============================] - 0s 827us/step\n",
      "1\n",
      "240/240 [==============================] - 0s 824us/step\n",
      "2\n",
      "240/240 [==============================] - 0s 763us/step\n",
      "3\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "4\n",
      "240/240 [==============================] - 0s 803us/step\n",
      "5\n",
      "240/240 [==============================] - 0s 756us/step\n",
      "6\n",
      "240/240 [==============================] - 0s 1ms/step\n",
      "7\n",
      "240/240 [==============================] - 0s 751us/step\n",
      "8\n",
      "240/240 [==============================] - 0s 791us/step\n",
      "9\n",
      "240/240 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#----- SET UP & TRAIN NN -----\n",
    "EXP_NAME = 'exp2'\n",
    "EXP_NAME2 = 'exp2_retrain_increase'\n",
    "hps2 = get_hp(EXP_NAME2)\n",
    "\n",
    "GLOBAL_SEED = hps2['GLOBAL_SEED']\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "tf.random.set_seed(GLOBAL_SEED)\n",
    "\n",
    "print('Validation Member: '+str(hps2['val_mems'][0]))\n",
    "print('Testing Member: '+str(hps2['test_mems'][0]))\n",
    "\n",
    "for i_trainmems in np.arange(3,9):\n",
    "    print(i_trainmems)\n",
    "    print('Training Members: '+str(hps2['train_mems'][i_trainmems]))\n",
    "\n",
    "    _, _, X1test, _, _, Y1test,_ = split_retrain(trainmems = hps2['train_mems'][i_trainmems],\n",
    "                                                  valmem = hps2['val_mems'][0],\n",
    "                                                  testmem = hps2['test_mems'][0],\n",
    "                                                  months = [11,12,1,2], # months for X (Y+leadtime are accounted for in function)\n",
    "                                                  lead = hps2['LEAD'])\n",
    "\n",
    "    nlat = X1test.shape[1]\n",
    "    nlon = X1test.shape[2]\n",
    "    X1test = X1test.reshape((X1test.shape[0],nlat*nlon))\n",
    "    number_inputs = nlat*nlon\n",
    "    \n",
    "    for SEED in np.arange(0,10):\n",
    "        IG_neg_heatmap = []\n",
    "        IG_pos_heatmap = []\n",
    "        print(SEED)\n",
    "        annfi_name = 'ann2_60Eshift_'+EXP_NAME2+'.'+str(i_trainmems)+'_ann1-'+EXP_NAME+'_seed'+str(SEED)+'.h5'\n",
    "        model = tf.keras.models.load_model(base_dir+'train/saved_models/'+annfi_name)\n",
    "        \n",
    "        pred = model.predict(X1test)\n",
    "        predconf = np.max(pred,axis=-1)\n",
    "        predval  = np.argmax(pred,axis=-1)\n",
    "    \n",
    "        iconf = np.where(predconf >= np.percentile(predconf,q=80))\n",
    "        icorr = np.where(predval[iconf] == Y1test[iconf])\n",
    "        \n",
    "        ineg = np.where(Y1test[iconf][icorr] == 0)\n",
    "        ipos = np.where(Y1test[iconf][icorr] == 1)\n",
    "        \n",
    "        # print(len(ineg[0]))\n",
    "        # print(len(ipos[0]))\n",
    "        \n",
    "        if len(ineg[0]) > 0:\n",
    "            for neg_sample in X1test[iconf][icorr][ineg]:\n",
    "                IG_negsample_heatmap = get_integrated_gradients(neg_sample.reshape((1,number_inputs)),top_pred_idx=0).numpy()[0]\n",
    "                IG_neg_heatmap.append(IG_negsample_heatmap/np.max(np.abs(IG_negsample_heatmap)))\n",
    "            \n",
    "            IG_neg_heatmap_reshape = np.asarray(IG_neg_heatmap).reshape((len(ineg[0]),nlat,nlon))\n",
    "            np.save(base_dir+'IG/data/IG_ann2_60Eshift_'+EXP_NAME2+'.'+str(i_trainmems)+'_ann1-'+EXP_NAME+'_negconf_seed'+str(SEED)+'.npy',\n",
    "                    IG_neg_heatmap_reshape,\n",
    "                    allow_pickle=True)\n",
    "        \n",
    "        if len(ipos[0]) > 0:\n",
    "            for pos_sample in X1test[iconf][icorr][ipos]:\n",
    "                IG_possample_heatmap = get_integrated_gradients(pos_sample.reshape((1,number_inputs)),top_pred_idx=1).numpy()[0]\n",
    "                IG_pos_heatmap.append(IG_possample_heatmap/np.max(np.abs(IG_possample_heatmap)))\n",
    "                \n",
    "            IG_pos_heatmap_reshape = np.asarray(IG_pos_heatmap).reshape((len(ipos[0]),nlat,nlon))\n",
    "            np.save(base_dir+'IG/data/IG_ann2_60Eshift_'+EXP_NAME2+'.'+str(i_trainmems)+'_ann1-'+EXP_NAME+'_posconf_seed'+str(SEED)+'.npy',\n",
    "                    IG_pos_heatmap_reshape,\n",
    "                    allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5836d31f-324e-4756-8733-c605b8c962ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IG_neg_heatmap_mean = np.mean(np.asarray(IG_neg_heatmap).reshape((len(ineg[0]),nlat,nlon)),0)\n",
    "# IG_pos_heatmap_mean = np.mean(IG_pos_heatmap_reshape,0)#np.asarray(IG_pos_heatmap).reshape((len(ipos[0]),nlat,nlon)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421e65de-6199-4693-acc5-9f2f98de9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(IG_neg_heatmap_mean,origin='lower',cmap='RdBu_r',vmin=-.1,vmax=.1)\n",
    "# plt.title('Unbiased Testing Member - After TL')\n",
    "# plt.show()\n",
    "# plt.imshow(IG_pos_heatmap_mean,origin='lower',cmap='RdBu_r',vmin=-.1,vmax=.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31160d04-e983-42ec-b0c6-8134aff9fd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2-env-v2]",
   "language": "python",
   "name": "conda-env-tf2-env-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
