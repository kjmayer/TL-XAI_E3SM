{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d20fd8a-a56d-4e54-8287-b57e17b37325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT:\n",
    "base_dir = '/glade/work/kjmayer/research/catalyst/TransferLearning/runmean_analysis/artificial_bias/perfectmodel_TLtest/E3SM_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fe5336-4843-4902-9c71-0787994c0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 09:17:52.593520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 09:17:53.358225: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(base_dir+'functions/')\n",
    "from utils import split_retrain, plot_results\n",
    "from exp_hp import get_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01c4b3-7530-4920-9ef3-9e9707fb1d81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ed1ddb-e257-4a9e-80ff-63be04664971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- LEARNING RATE CALLBACK FUNCTION ----------------\n",
    "# def scheduler(epoch, lr):\n",
    "#     # This function keeps the initial learning rate for the first ten epochs\n",
    "#     # and decreases it exponentially after that.\n",
    "#     if epoch > 10:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.constant(.9,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81d5b6d-38f7-458e-a5cb-73d327e697f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann2(input_shape,output_shape, hiddens, RIDGE = 0, dropout = True, dropout_rate = 0.0):\n",
    "    tf.keras.backend.clear_session() \n",
    "\n",
    "    # ----- input of cnn -----\n",
    "    ann_input = keras.Input(shape = input_shape)\n",
    "\n",
    "    for l,layer in enumerate(hiddens):\n",
    "        # ----- ann layers -----\n",
    "        if l == 0:\n",
    "            x = tf.keras.layers.Dense(layer, \n",
    "                                      activation = 'relu',\n",
    "                                      use_bias = True, \n",
    "                                      kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.0, l2=RIDGE),\n",
    "                                      bias_initializer = tf.keras.initializers.RandomNormal(seed=SEED),\n",
    "                                      kernel_initializer = tf.keras.initializers.RandomNormal(seed=SEED)\n",
    "                                      )(ann_input)\n",
    "            if dropout:\n",
    "                x = layers.Dropout(rate = dropout_rate)(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.Dense(layer, \n",
    "                                      activation = 'relu',\n",
    "                                      use_bias = True, \n",
    "                                      kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.0, l2=0.0),\n",
    "                                      bias_initializer = tf.keras.initializers.RandomNormal(seed=SEED),\n",
    "                                      kernel_initializer = tf.keras.initializers.RandomNormal(seed=SEED)\n",
    "                                      )(x)\n",
    "        \n",
    "    # ----- output -----\n",
    "    ann_output = tf.keras.layers.Dense(output_shape,\n",
    "                                       activation = tf.keras.activations.softmax,\n",
    "                                       use_bias = True,\n",
    "                                       kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.0, l2=0.0),\n",
    "                                       bias_initializer = tf.keras.initializers.RandomNormal(seed=SEED),\n",
    "                                       kernel_initializer = tf.keras.initializers.RandomNormal(seed=SEED)\n",
    "                                      )(x)\n",
    "    # ----- create unet -----\n",
    "    ann = keras.Model(ann_input, ann_output, name = 'ann')\n",
    "    \n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0843ffad-723f-4e96-b4c4-482f808a4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Training Members: ['0201', '0211', '0221', '0231', '0241', '0251', '0261']\n",
      "Validation Member: 0291\n",
      "Testing Member: 0301\n",
      "Lead: 14\n",
      "Region: 30-60N x 170-240E\n",
      "loading data & saving\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 09:18:22.630730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:85\u001b[0m\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/glade/work/kjmayer/conda-envs/tf2-env-v2/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EXP_NAME2 = 'exp2_retrain_increase'\n",
    "hps2 = get_hp(EXP_NAME2)\n",
    "EXP_NAME = 'exp2'\n",
    "hps = get_hp(EXP_NAME)\n",
    "\n",
    "for i_trainmems in np.arange(6,9):\n",
    "    print(i_trainmems)\n",
    "    print('Training Members: '+str(hps2['train_mems'][i_trainmems]))\n",
    "    print('Validation Member: '+str(hps2['val_mems'][0]))\n",
    "    print('Testing Member: '+str(hps2['test_mems'][0]))\n",
    "    print('Lead: '+str(hps2['LEAD']))\n",
    "    print('Region: '+str(hps2['region'][0])+'N x '+str(hps2['region'][1])+'E')\n",
    "\n",
    "    X2train, X2val, _, Y2train, Y2val, _, _ = split_retrain(trainmems = hps2['train_mems'][i_trainmems],\n",
    "                                                              valmem = hps2['val_mems'][0],\n",
    "                                                              testmem = hps2['test_mems'][0],\n",
    "                                                              months = [11,12,1,2], # months for X (Y+leadtime are accounted for in function)\n",
    "                                                              lead = hps2['LEAD']) # 330 or 210\n",
    "\n",
    "    X2val = X2val.reshape((X2val.shape[0],X2val.shape[1]*X2val.shape[2]))\n",
    "    X2train = X2train.reshape((X2train.shape[0],X2train.shape[1]*X2train.shape[2]))\n",
    "    input_shape = X2train.shape[1]\n",
    "\n",
    "    # ---------- ANN Hyperparameters ----------\n",
    "    NLABEL = 2\n",
    "    N_EPOCHS = 1000\n",
    "\n",
    "    hps = get_hp(EXP_NAME) # need to have this here because .extend overwrites HIDDENS\n",
    "\n",
    "    HIDDENS = hps['HIDDENS']    \n",
    "    GLOBAL_SEED = hps['GLOBAL_SEED']\n",
    "    # HIDDENS.extend(ann2HIDDENS)\n",
    "\n",
    "    ann2LR_INIT = hps2['LR_INIT'] \n",
    "    ann2BATCH_SIZE = hps2['BATCH_SIZE'] \n",
    "    ann2dropout_rate = hps2['DROPOUT_RATE'] \n",
    "    ann2RIDGE = hps2['RIDGE'] \n",
    "    PATIENCE = hps2['PATIENCE']\n",
    "\n",
    "    #----- SET UP & TRAIN NN -----\n",
    "    np.random.seed(GLOBAL_SEED)\n",
    "    random.seed(GLOBAL_SEED)\n",
    "    tf.random.set_seed(GLOBAL_SEED)\n",
    "\n",
    "    for SEED in range(10):\n",
    "        print(SEED)\n",
    "        tf.keras.backend.clear_session() \n",
    "\n",
    "        # ------ define NN ------\n",
    "        ann2 = create_ann2(input_shape = input_shape,\n",
    "                           output_shape = NLABEL,\n",
    "                           hiddens=HIDDENS,\n",
    "                           RIDGE = ann2RIDGE,\n",
    "                           dropout = True, dropout_rate = ann2dropout_rate)\n",
    "\n",
    "        annfi_name = 'ann_60Eshift_'+EXP_NAME+'_seed'+str(SEED)+'.h5'\n",
    "        ann1 = tf.keras.models.load_model(base_dir+'train/saved_models/'+annfi_name)\n",
    "\n",
    "        ## For exp1:\n",
    "        # for l in [1]:#,3]: #layers 1 & 3 have weights in ann1 (4 also has weight but we are removing final layer); layer 2 is dropout\n",
    "        #     ann2.layers[l].set_weights(ann1.layers[l].get_weights()) #[:-1*(len(ann2HIDDENS)+1)][l].set_weights(ann1.layers[:-1][l].get_weights())\n",
    "        #     # ann2.layers[:-1*(len(ann2HIDDENS)+1)][l].trainable = False\n",
    "\n",
    "        ann2.layers[1].set_weights(ann1.layers[1].get_weights())\n",
    "\n",
    "        # ann2.summary()\n",
    "\n",
    "        # ------ Training Hyperparameters ------\n",
    "        optimizer = tf.optimizers.Adam(learning_rate = ann2LR_INIT,)\n",
    "        loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"sparse_categorical_accuracy\", dtype=None)]                             \n",
    "\n",
    "        # ------ Compile Model -----\n",
    "        ann2.compile(optimizer = optimizer,\n",
    "                    loss = loss_func,\n",
    "                    metrics = metrics)\n",
    "\n",
    "        # ----- Callbacks -----\n",
    "        ES = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'auto', min_delta = 0.001,\n",
    "                                              patience = PATIENCE, verbose = 0, restore_best_weights = True)\n",
    "        # LR = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=0)\n",
    "\n",
    "        # ------ Train -----\n",
    "        start_time = time.time()\n",
    "        history = ann2.fit(X2train,Y2train,\n",
    "                          validation_data = [X2val,Y2val],\n",
    "                          batch_size = ann2BATCH_SIZE,\n",
    "                          epochs = N_EPOCHS,\n",
    "                          shuffle = True,\n",
    "                          verbose = 0,\n",
    "                          callbacks = [ES])#,LR])\n",
    "        stop_time = time.time()\n",
    "        tf.print(f\"Elapsed time during fit = {(stop_time - start_time)/60.:.2f} minutes\\n\")\n",
    "\n",
    "        #----- PLOT THE RESULTS -----\n",
    "        if SEED == 0:\n",
    "            plot_results(\n",
    "                history,\n",
    "                exp_info=(100, HIDDENS, ann2LR_INIT, ann2BATCH_SIZE, SEED, PATIENCE, ann2RIDGE),\n",
    "                showplot=True\n",
    "            ) \n",
    "            \n",
    "        annfi_name = 'ann2_60Eshift_'+EXP_NAME2+'.'+str(i_trainmems)+'_ann1-'+EXP_NAME+'_seed'+str(SEED)+'.h5'\n",
    "        ann2.save(base_dir+'train/saved_models/'+annfi_name)\n",
    "        \n",
    "        if SEED == 9:\n",
    "            pred1 = np.argmax(ann1.predict(X2val),axis=-1)\n",
    "            pred2 = np.argmax(ann2.predict(X2val),axis=-1)\n",
    "\n",
    "            print((np.shape(np.where(pred1==Y2val)[0])[0]/np.shape(Y2val)[0])*100) # og network \n",
    "            print((np.shape(np.where(pred2==Y2val)[0])[0]/np.shape(Y2val)[0])*100) # first layer weights transferred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1d120-8ffd-41ed-acea-3c6b6c0df229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3be89-c704-47ed-90f1-3d1f12f04a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2-env-v2]",
   "language": "python",
   "name": "conda-env-tf2-env-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
